{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport matplotlib.pyplot as plt\nimport glob\nimport cv2\n\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (\n    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n)\nfrom tensorflow.keras import backend as K\nimport os\nimport seaborn as sns\nfrom keras.applications.vgg16 import VGG16","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing data","metadata":{}},{"cell_type":"code","source":"data_dir = \"../input/leafsnap-vgg16-2/field\"\n\nroot, dirs, files = next(os.walk(data_dir), ([],[],[]))\ndirs.sort()\nprint(len(dirs))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resising the image","metadata":{}},{"cell_type":"code","source":"def resize(fl, img_height, img_width):\n    img = cv2.imread(fl)\n    resized = cv2.resize(img, (img_height, img_width))\n    return resized","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making Data","metadata":{}},{"cell_type":"code","source":"def get_data():\n    X = []\n    y = []\n    classes = []\n    dir_names = []\n    \n    for dir_name in dirs[:30]:\n        class_name = dir_name.replace('_','')\n        classes.append(class_name)\n        \n        dir_names.append(dir_name)\n        \n        path = os.path.join(data_dir,dir_name,'*.jpg')\n        images = glob.glob(path)\n        \n        for fl in images:\n            flbase = os.path.basename(fl)\n            img = resize(fl, 120, 120)\n            X.append(img)\n            y.append(class_name)\n            \n    return X, y, classes,dir_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels, classes,dir_names = get_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert lists to arrays        \nimages = np.array(images)\nlabels = np.array(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transforming labels to numerical using label encoder","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split, cross_val_score\nle = preprocessing.LabelEncoder()\nle.fit(labels)\ntrain_labels_encoded = le.transform(labels)\n\n#Split data into test and train datasets (already split but assigning to meaningful convention)\nx_train,x_test,y_train, y_test = train_test_split(images, train_labels_encoded, test_size=0.3, random_state=0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VGG","metadata":{}},{"cell_type":"code","source":"SIZE=120\nVGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n\n#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\nfor layer in VGG_model.layers:\n\tlayer.trainable = False\n    \nVGG_model.summary()  #Trainable parameters will be 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_extractor=VGG_model.predict(x_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n\nX_for_model = features #This is our X input to RF","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LogReg with features extracted using VGG","metadata":{"execution":{"iopub.status.busy":"2021-12-07T05:51:29.371688Z","iopub.execute_input":"2021-12-07T05:51:29.371993Z","iopub.status.idle":"2021-12-07T05:51:29.376971Z","shell.execute_reply.started":"2021-12-07T05:51:29.371961Z","shell.execute_reply":"2021-12-07T05:51:29.376015Z"}}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\n\n# Define the train/test loss metric as MSE\ndef mse(y,ypr):\n    return np.mean((y-ypr)**2)\n\n\n# define shuffled KFold crossvalidation object\nkf = KFold(n_splits=5, shuffle=False)\n\n# define you scorer\nscr = make_scorer(mse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\n\nlr_mod1 = Pipeline([\n    ('mod1', LogisticRegression(penalty='none',max_iter = 10000,solver='lbfgs'))\n])\n\n\nlr_mod2 = Pipeline([\n    ('mod2',LogisticRegression(penalty=\"l2\", C=1,solver=\"sag\"))\n])\n\nlr_mod3 = Pipeline([\n    ('mod3', LogisticRegression(penalty='l1', solver='liblinear', C=0.01))\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate mean CV scores for each model \nCV1 = cross_val_score(lr_mod1, X_for_model, y_train, cv=kf, scoring=scr).mean()\nCV3 = cross_val_score(lr_mod3, X_for_model, y_train, cv=kf, scoring=scr).mean()\nCV2 = cross_val_score(lr_mod2, X_for_model, y_train, cv=kf, scoring=scr).mean()\n\n\nprint(f\"CV loss (L2 penalised Model): {CV2}\")\nprint(f\"CV loss (NonPenalised LR Model): {CV1}\")\nprint(f\"CV loss (L1 Penalised Model): {CV3}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The L2 penalty shows the least CV loss. Hence we go with the `L2` penalised model","metadata":{}},{"cell_type":"markdown","source":"#### We need to also find the best `C` paramter","metadata":{}},{"cell_type":"code","source":"lam = np.exp(np.linspace(-1,1,10))\nerrs = np.zeros(len(lam))\n\nfor i in range(len(lam)):\n    lr_mod2.set_params(mod2=LogisticRegression(C=lam[i], penalty='l2'))\n    cvsc = cross_val_score(lr_mod2, X_for_model, y_train,cv=10,scoring =scr)\n    errs[i] = cvsc.mean()\n    print(f\"C-value (1/lam): {lam[i]} | nll: {errs[i]}\")\n    \na = np.array([lam,errs])\nbest_C = a[0,np.argmin(np.abs(a),axis=1)[1]]\nprint(f\"Optimal lambda: {best_C}\")\n\n# Let's evaluate a final model with a confusion matrix, and one additional metric\nlr_mod2.set_params(mod2=LogisticRegression(C=best_C, penalty='l2'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Find the `prediction` of the model","metadata":{}},{"cell_type":"code","source":"# #Send test data through same feature extractor process\nX_test_feature = VGG_model.predict(x_test)\nX_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_modt = LogisticRegression(penalty=\"l2\", C=best_C,solver=\"sag\")\nfinal_modt.fit(X_for_model,y_train)\nypred = final_modt.predict(X_test_features)\nypred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Find the prediction accuracy, recall & prediction scores","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV, KFold\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, roc_curve, auc\nfrom sklearn.model_selection import train_test_split\n# from matplotlib.colors import ListedColormapim\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the prediction accuracy score\nacc = accuracy_score(y_test,ypred)\nprint(\"Accuracy :\", acc)\n\n# Find the recall, precision scores\nrec = recall_score(y_test,ypred, average='macro')\nprec = precision_score(y_test,ypred, average='macro')\n# print(\"\\n\")\nprint(f\"Recall: {rec}, \\nPrecision: {prec}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Finding the ROC performance of the model","metadata":{}},{"cell_type":"code","source":"def plot_multiclass_roc(clf, xtest, ytest, n_classes, figsize=(17, 6)):\n    y_score = clf.predict_proba(xtest)\n\n    # structures\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    # calculate dummies once\n    y_test_dummies = pd.get_dummies(ytest, drop_first=False).values\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # roc for each class\n    fig, ax = plt.subplots(figsize=figsize)\n    ax.plot([0, 1], [0, 1], 'k--')\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel('False Positive Rate')\n    ax.set_ylabel('True Positive Rate')\n    ax.set_title('Receiver operating characteristic example')\n    for i in range(n_classes):\n        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n    ax.legend(loc=\"best\")\n    ax.grid(alpha=.4)\n    sns.despine()\n    plt.show()\n    plt.savefig('VGG16_LR_roc.png')\n    \nplot_multiclass_roc(final_modt, X_test_features, y_test, n_classes=30, figsize=(10,9))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\nfig, ax1 = plt.subplots(1,1, figsize=(10,7))\nconf = confusion_matrix(y_test,ypred)\nsns.heatmap(conf, annot=True, cbar=False, fmt=\"d\", linewidths=0.5, cmap=\"plasma_r\", ax=ax1)\nax1.set_title(\"Confusion Label\")\nax1.set_xlabel(\"Predicted Class\")\nax1.set_ylabel(\"Original Class\")\nfig.tight_layout\nfig.savefig('VGG16_LR_ConfMatrix.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = le.inverse_transform(ypred)\ny_test = le.inverse_transform(y_test)\n\nprint(classification_report(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}